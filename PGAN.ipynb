{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "name": "PGAN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/Progressive-GAN-pytorch/blob/lightning/PGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93477e7c"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import argparse\n",
        "import random"
      ],
      "id": "93477e7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cec3df4"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable, grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils"
      ],
      "id": "8cec3df4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1a0fb71"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "id": "e1a0fb71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc39429c"
      },
      "source": [
        "from math import sqrt"
      ],
      "id": "dc39429c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9c31b64"
      },
      "source": [
        "class EqualLR:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "\n",
        "    def compute_weight(self, module):\n",
        "        weight = getattr(module, self.name + '_orig')\n",
        "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
        "\n",
        "        return weight * sqrt(2 / fan_in)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply(module, name):\n",
        "        fn = EqualLR(name)\n",
        "\n",
        "        weight = getattr(module, name)\n",
        "        del module._parameters[name]\n",
        "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
        "        module.register_forward_pre_hook(fn)\n",
        "\n",
        "        return fn\n",
        "\n",
        "    def __call__(self, module, input):\n",
        "        weight = self.compute_weight(module)\n",
        "        setattr(module, self.name, weight)"
      ],
      "id": "d9c31b64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a75e0da3"
      },
      "source": [
        "def equal_lr(module, name='weight'):\n",
        "    EqualLR.apply(module, name)\n",
        "\n",
        "    return module"
      ],
      "id": "a75e0da3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cfde1dc"
      },
      "source": [
        "class PixelNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
        "                                  + 1e-8)"
      ],
      "id": "2cfde1dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07f237f8"
      },
      "source": [
        "class EqualConv2d(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.weight.data.normal_()\n",
        "        self.bias.data.zero_()\n",
        "        self = equal_lr(self)"
      ],
      "id": "07f237f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "e199610f"
      },
      "source": [
        "class EqualConvTranspose2d(nn.ConvTranspose2d):\n",
        "    ### additional module for OOGAN usage\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.weight.data.normal_()\n",
        "        self.bias.data.zero_()\n",
        "        self = equal_lr(self)"
      ],
      "id": "e199610f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1f05b18"
      },
      "source": [
        "class EqualLinear(nn.Linear):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__(in_dim, out_dim)\n",
        "\n",
        "        self.weight.data.normal_()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "        self = equal_lr(self)"
      ],
      "id": "e1f05b18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e19f002"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None, pixel_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        pad1 = padding\n",
        "        pad2 = padding\n",
        "        if padding2 is not None:\n",
        "            pad2 = padding2\n",
        "\n",
        "        kernel1 = kernel_size\n",
        "        kernel2 = kernel_size\n",
        "        if kernel_size2 is not None:\n",
        "            kernel2 = kernel_size2\n",
        "\n",
        "        convs = [EqualConv2d(in_channel, out_channel, kernel1, padding=pad1)]\n",
        "        if pixel_norm:\n",
        "            convs.append(PixelNorm())\n",
        "        convs.append(nn.LeakyReLU(0.1))\n",
        "        convs.append(EqualConv2d(out_channel, out_channel, kernel2, padding=pad2))\n",
        "        if pixel_norm:\n",
        "            convs.append(PixelNorm())\n",
        "        convs.append(nn.LeakyReLU(0.1))\n",
        "\n",
        "        self.conv = nn.Sequential(*convs)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv(input)\n",
        "        return out"
      ],
      "id": "1e19f002",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "92eebb56"
      },
      "source": [
        "def upscale(feat):\n",
        "    return F.interpolate(feat, scale_factor=2, align_corners=False)"
      ],
      "id": "92eebb56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80be0f42"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_code_dim=128, in_channel=128, pixel_norm=True, tanh=True):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_code_dim\n",
        "        self.tanh = tanh\n",
        "        self.input_layer = nn.Sequential(\n",
        "            EqualConvTranspose2d(input_code_dim, in_channel, 4, 1, 0),\n",
        "            PixelNorm(),\n",
        "            nn.LeakyReLU(0.1))\n",
        "\n",
        "        self.progression_4 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_8 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_16 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_32 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_64 = ConvBlock(in_channel, in_channel//2, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_128 = ConvBlock(in_channel//2, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
        "        self.progression_256 = ConvBlock(in_channel//4, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
        "\n",
        "        self.to_rgb_8 = EqualConv2d(in_channel, 1, 1)\n",
        "        self.to_rgb_16 = EqualConv2d(in_channel, 1, 1)\n",
        "        self.to_rgb_32 = EqualConv2d(in_channel, 1, 1)\n",
        "        self.to_rgb_64 = EqualConv2d(in_channel//2, 1, 1)\n",
        "        self.to_rgb_128 = EqualConv2d(in_channel//4, 1, 1)\n",
        "        self.to_rgb_256 = EqualConv2d(in_channel//4, 1, 1)\n",
        "        \n",
        "        self.max_step = 6\n",
        "\n",
        "    def progress(self, feat, module):\n",
        "        out = F.interpolate(feat, scale_factor=2, align_corners=False)\n",
        "        out = module(out)\n",
        "        return out\n",
        "\n",
        "    def output(self, feat1, feat2, module1, module2, alpha):\n",
        "        if 0 <= alpha < 1:\n",
        "            skip_rgb = upscale(module1(feat1))\n",
        "            out = (1-alpha)*skip_rgb + alpha*module2(feat2)\n",
        "        else:\n",
        "            out = module2(feat2)\n",
        "        if self.tanh:\n",
        "            return torch.tanh(out)\n",
        "        return out\n",
        "\n",
        "    def forward(self, input, step=0, alpha=-1):\n",
        "        if step > self.max_step:\n",
        "            step = self.max_step\n",
        "\n",
        "        out_4 = self.input_layer(input.view(-1, self.input_dim, 1, 1))\n",
        "        out_4 = self.progression_4(out_4)\n",
        "        out_8 = self.progress(out_4, self.progression_8)\n",
        "        if step==1:\n",
        "            if self.tanh:\n",
        "                return torch.tanh(self.to_rgb_8(out_8))\n",
        "            return self.to_rgb_8(out_8)\n",
        "        \n",
        "        out_16 = self.progress(out_8, self.progression_16)\n",
        "        if step==2:\n",
        "            return self.output( out_8, out_16, self.to_rgb_8, self.to_rgb_16, alpha )\n",
        "        \n",
        "        out_32 = self.progress(out_16, self.progression_32)\n",
        "        if step==3:\n",
        "            return self.output( out_16, out_32, self.to_rgb_16, self.to_rgb_32, alpha )\n",
        "\n",
        "        out_64 = self.progress(out_32, self.progression_64)\n",
        "        if step==4:\n",
        "            return self.output( out_32, out_64, self.to_rgb_32, self.to_rgb_64, alpha )\n",
        "        \n",
        "        out_128 = self.progress(out_64, self.progression_128)\n",
        "        if step==5:\n",
        "            return self.output( out_64, out_128, self.to_rgb_64, self.to_rgb_128, alpha )\n",
        "\n",
        "        out_256 = self.progress(out_128, self.progression_256)\n",
        "        if step==6:\n",
        "            return self.output( out_128, out_256, self.to_rgb_128, self.to_rgb_256, alpha )"
      ],
      "id": "80be0f42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fd61ae3"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, feat_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.progression = nn.ModuleList([ConvBlock(feat_dim//4, feat_dim//4, 3, 1),\n",
        "                                          ConvBlock(feat_dim//4, feat_dim//2, 3, 1),\n",
        "                                          ConvBlock(feat_dim//2, feat_dim, 3, 1),\n",
        "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
        "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
        "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
        "                                          ConvBlock(feat_dim+1, feat_dim, 3, 1, 4, 0)])\n",
        "\n",
        "        self.from_rgb = nn.ModuleList([EqualConv2d(1, feat_dim//4, 1),\n",
        "                                       EqualConv2d(1, feat_dim//4, 1),\n",
        "                                       EqualConv2d(1, feat_dim//2, 1),\n",
        "                                       EqualConv2d(1, feat_dim, 1),\n",
        "                                       EqualConv2d(1, feat_dim, 1),\n",
        "                                       EqualConv2d(1, feat_dim, 1),\n",
        "                                       EqualConv2d(1, feat_dim, 1)])\n",
        "\n",
        "        self.n_layer = len(self.progression)\n",
        "\n",
        "        self.linear = EqualLinear(feat_dim, 1)\n",
        "\n",
        "    def forward(self, input, step=0, alpha=-1):\n",
        "        for i in range(step, -1, -1):\n",
        "            index = self.n_layer - i - 1\n",
        "\n",
        "            if i == step:\n",
        "                out = self.from_rgb[index](input)\n",
        "\n",
        "            if i == 0:\n",
        "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
        "                mean_std = out_std.mean()\n",
        "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
        "                out = torch.cat([out, mean_std], 1)\n",
        "\n",
        "            out = self.progression[index](out)\n",
        "\n",
        "            if i > 0:\n",
        "                # out = F.avg_pool2d(out, 2)\n",
        "                out = F.interpolate(out, scale_factor=0.5, align_corners=False)\n",
        "\n",
        "                if i == step and 0 <= alpha < 1:\n",
        "                    # skip_rgb = F.avg_pool2d(input, 2)\n",
        "                    skip_rgb = F.interpolate(input, scale_factor=0.5, align_corners=False)\n",
        "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
        "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
        "\n",
        "        out = out.squeeze(2).squeeze(2)\n",
        "        # print(input.size(), out.size(), step)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ],
      "id": "9fd61ae3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb8407c"
      },
      "source": [
        "def accumulate(model1, model2, decay=0.999):\n",
        "    par1 = dict(model1.named_parameters())\n",
        "    par2 = dict(model2.named_parameters())\n",
        "\n",
        "    for k in par1.keys():\n",
        "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)"
      ],
      "id": "feb8407c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9b92335"
      },
      "source": [
        "def imagefolder_loader(path):\n",
        "    def npy_loader(path):\n",
        "        # s=np.load(path).astype('float',copy=False)\n",
        "        return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "\n",
        "    def loader(transform):\n",
        "        data = datasets.DatasetFolder(path, npy_loader, ('.npy'), transform=transform)\n",
        "        data_loader = DataLoader(data, shuffle=True, batch_size=batch_size,\n",
        "                                 num_workers=4)\n",
        "        return data_loader\n",
        "    return loader"
      ],
      "id": "d9b92335",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce63205e"
      },
      "source": [
        "def sample_data(dataloader, image_size=4):\n",
        "    GLOBAL = np.load('/content/GLOBAL_VALS_F.npz')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Normalize((GLOBAL['VALS'][2]), (GLOBAL['VALS'][3])),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "        transforms.Resize(image_size, transforms.InterpolationMode.NEAREST),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "    ])\n",
        "\n",
        "    loader = dataloader(transform)\n",
        "\n",
        "    return loader"
      ],
      "id": "ce63205e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "9b50d80e"
      },
      "source": [
        "def train(generator, discriminator, init_step, loader, total_iter=600000):\n",
        "    step = init_step # can be 1 = 8, 2 = 16, 3 = 32, 4 = 64, 5 = 128, 6 = 128\n",
        "    data_loader = sample_data(loader, 4 * 2 ** step)\n",
        "    dataset = iter(data_loader)\n",
        "\n",
        "    #total_iter = 600000\n",
        "    total_iter_remain = total_iter - (total_iter//6)*(step-1)\n",
        "\n",
        "    pbar = tqdm(range(total_iter_remain))\n",
        "\n",
        "    disc_loss_val = 0\n",
        "    gen_loss_val = 0\n",
        "    grad_loss_val = 0\n",
        "\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "    date_time = datetime.now()\n",
        "    post_fix = '%s_%s_%d_%d.txt'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
        "    log_folder = 'trial_%s_%s_%d_%d'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
        "    \n",
        "    os.mkdir(log_folder)\n",
        "    os.mkdir(log_folder+'/checkpoint')\n",
        "    os.mkdir(log_folder+'/sample')\n",
        "\n",
        "    config_file_name = os.path.join(log_folder, 'train_config_'+post_fix)\n",
        "    config_file = open(config_file_name, 'w')\n",
        "    config_file.write(str(args))\n",
        "    config_file.close()\n",
        "\n",
        "    log_file_name = os.path.join(log_folder, 'train_log_'+post_fix)\n",
        "    log_file = open(log_file_name, 'w')\n",
        "    log_file.write('g,d,nll,onehot\\n')\n",
        "    log_file.close()\n",
        "\n",
        "    from shutil import copy\n",
        "    copy('train.py', log_folder+'/train_%s.py'%post_fix)\n",
        "    copy('progan_modules.py', log_folder+'/model_%s.py'%post_fix)\n",
        "\n",
        "    alpha = 0\n",
        "    #one = torch.FloatTensor([1]).to(device)\n",
        "    one = torch.tensor(1, dtype=torch.float).to(device)\n",
        "    mone = one * -1\n",
        "    iteration = 0\n",
        "\n",
        "    for i in pbar:\n",
        "        discriminator.zero_grad()\n",
        "\n",
        "        alpha = min(1, (2/(total_iter//6)) * iteration)\n",
        "\n",
        "        if iteration > total_iter//6:\n",
        "            alpha = 0\n",
        "            iteration = 0\n",
        "            step += 1\n",
        "\n",
        "            if step > 6:\n",
        "                alpha = 1\n",
        "                step = 6\n",
        "            data_loader = sample_data(loader, 4 * 2 ** step)\n",
        "            dataset = iter(data_loader)\n",
        "\n",
        "        try:\n",
        "            real_image, label = next(dataset)\n",
        "\n",
        "        except (OSError, StopIteration):\n",
        "            dataset = iter(data_loader)\n",
        "            real_image, label = next(dataset)\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "        ### 1. train Discriminator\n",
        "        b_size = real_image.size(0)\n",
        "        real_image = real_image.to(device)\n",
        "        label = label.to(device)\n",
        "        real_predict = discriminator(\n",
        "            real_image, step=step, alpha=alpha)\n",
        "        real_predict = real_predict.mean() \\\n",
        "            - 0.001 * (real_predict ** 2).mean()\n",
        "        real_predict.backward(mone)\n",
        "\n",
        "        # sample input data: vector for Generator\n",
        "        gen_z = torch.randn(b_size, input_code_size).to(device)\n",
        "\n",
        "        fake_image = generator(gen_z, step=step, alpha=alpha)\n",
        "        fake_predict = discriminator(\n",
        "            fake_image.detach(), step=step, alpha=alpha)\n",
        "        fake_predict = fake_predict.mean()\n",
        "        fake_predict.backward(one)\n",
        "\n",
        "        ### gradient penalty for D\n",
        "        eps = torch.rand(b_size, 1, 1, 1).to(device)\n",
        "        x_hat = eps * real_image.data + (1 - eps) * fake_image.detach().data\n",
        "        x_hat.requires_grad = True\n",
        "        hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
        "        grad_x_hat = grad(\n",
        "            outputs=hat_predict.sum(), inputs=x_hat, create_graph=True)[0]\n",
        "        grad_penalty = ((grad_x_hat.view(grad_x_hat.size(0), -1)\n",
        "                         .norm(2, dim=1) - 1)**2).mean()\n",
        "        grad_penalty = 10 * grad_penalty\n",
        "        grad_penalty.backward()\n",
        "        grad_loss_val += grad_penalty.item()\n",
        "        disc_loss_val += (real_predict - fake_predict).item()\n",
        "\n",
        "        d_optimizer.step()\n",
        "\n",
        "        ### 2. train Generator\n",
        "        if (i + 1) % n_critic == 0:\n",
        "            generator.zero_grad()\n",
        "            discriminator.zero_grad()\n",
        "            \n",
        "            predict = discriminator(fake_image, step=step, alpha=alpha)\n",
        "\n",
        "            loss = -predict.mean()\n",
        "            gen_loss_val += loss.item()\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            g_optimizer.step()\n",
        "            accumulate(g_running, generator)\n",
        "\n",
        "        if (i + 1) % 1000 == 0 or i==0:\n",
        "            with torch.no_grad():\n",
        "                images = g_running(torch.randn(5 * 10, input_code_size).to(device), step=step, alpha=alpha).data.cpu()\n",
        "\n",
        "                utils.save_image(\n",
        "                    images,\n",
        "                    f'{log_folder}/sample/{str(i + 1).zfill(6)}.png',\n",
        "                    nrow=10,\n",
        "                    normalize=True,\n",
        "                    range=(-1, 1))\n",
        " \n",
        "        if (i+1) % 10000 == 0 or i==0:\n",
        "            try:\n",
        "                torch.save(g_running.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_g.model')\n",
        "                torch.save(discriminator.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_d.model')\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        if (i+1)%500 == 0:\n",
        "            state_msg = (f'{i + 1}; G: {gen_loss_val/(500//n_critic):.3f}; D: {disc_loss_val/500:.3f};'\n",
        "                f' Grad: {grad_loss_val/500:.3f}; Alpha: {alpha:.3f}')\n",
        "            \n",
        "            log_file = open(log_file_name, 'a+')\n",
        "            new_line = \"%.5f,%.5f\\n\"%(gen_loss_val/(500//n_critic), disc_loss_val/500)\n",
        "            log_file.write(new_line)\n",
        "            log_file.close()\n",
        "\n",
        "            disc_loss_val = 0\n",
        "            gen_loss_val = 0\n",
        "            grad_loss_val = 0\n",
        "\n",
        "            print(state_msg)\n",
        "            #pbar.set_description(state_msg)"
      ],
      "id": "9b50d80e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afb50887"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Progressive GAN, during training, the model will learn to generate  images from a low resolution, then progressively getting high resolution ')\n",
        "\n",
        "    parser.add_argument('--path', type=str, help='path of specified dataset, should be a folder that has one or many sub image folders inside')\n",
        "    parser.add_argument('--trial_name', type=str, default=\"test1\", help='a brief description of the training trial')\n",
        "    parser.add_argument('--gpu_id', type=int, default=0, help='0 is the first gpu, 1 is the second gpu, etc.')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate, default is 1e-3, usually dont need to change it, you can try make it bigger, such as 2e-3')\n",
        "    parser.add_argument('--z_dim', type=int, default=128, help='the initial latent vector\\'s dimension, can be smaller such as 64, if the dataset is not diverse')\n",
        "    parser.add_argument('--channel', type=int, default=128, help='determines how big the model is, smaller value means faster training, but less capacity of the model')\n",
        "    parser.add_argument('--batch_size', type=int, default=4, help='how many images to train together at one iteration')\n",
        "    parser.add_argument('--n_critic', type=int, default=1, help='train Dhow many times while train G 1 time')\n",
        "    parser.add_argument('--init_step', type=int, default=1, help='start from what resolution, 1 means 8x8 resolution, 2 means 16x16 resolution, ..., 6 means 256x256 resolution')\n",
        "    parser.add_argument('--total_iter', type=int, default=300000, help='how many iterations to train in total, the value is in assumption that init step is 1')\n",
        "    parser.add_argument('--pixel_norm', default=False, action=\"store_true\", help='a normalization method inside the model, you can try use it or not depends on the dataset')\n",
        "    parser.add_argument('--tanh', default=False, action=\"store_true\", help='an output non-linearity on the output of Generator, you can try use it or not depends on the dataset')\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(str(args))\n",
        "\n",
        "    trial_name = args.trial_name\n",
        "    device = torch.device(\"cuda:%d\"%(args.gpu_id))\n",
        "    input_code_size = args.z_dim\n",
        "    batch_size = args.batch_size\n",
        "    n_critic = args.n_critic\n",
        "\n",
        "    generator = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)\n",
        "    discriminator = Discriminator(feat_dim=args.channel).to(device)\n",
        "    g_running = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)\n",
        "    \n",
        "    ## you can directly load a pretrained model here\n",
        "    #generator.load_state_dict(torch.load('./tr checkpoint/150000_g.model'))\n",
        "    #g_running.load_state_dict(torch.load('checkpoint/150000_g.model'))\n",
        "    #discriminator.load_state_dict(torch.load('checkpoint/150000_d.model'))\n",
        "    \n",
        "    g_running.train(False)\n",
        "\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
        "\n",
        "    accumulate(g_running, generator, 0)\n",
        "\n",
        "    loader = imagefolder_loader(args.path)\n",
        "\n",
        "    train(generator, discriminator, args.init_step, loader, args.total_iter)"
      ],
      "id": "afb50887",
      "execution_count": null,
      "outputs": []
    }
  ]
}